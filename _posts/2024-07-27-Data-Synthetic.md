---
title: "Is Model Collapse Inevitable?"
date: 2024-07-27T00:00-00:00
last_modified_at: 2024-07-27T00:00-00:00
categories:
  - code
  - deep learning
permalink: /model-collapse/
classes: wide
excerpt: Generation Model
header:
  og_image: /images/ensemble_learning_intro.jpg
  teaser: /images/ensemble_learning_intro.jpg
---
> ## Table of Contents
> 
> 1.  [Tóm lược paper](#tóm-lược-paper)
> 2.  [Một số vấn đề](#một-số-vấn-đề)

Đây là bài viết luận bàn từ 1 post trên [Twitter](https://x.com/alexandr_wang/status/1816491442069782925). Chủ đề chính của bài post xoay quanh chủ đề **Model Collapse** (nghĩa ở đây tạm hiểu là model ngu đi :)). Sau khi đọc qua một vài bài repost hay reply bài này thì mình thấy được một số luận điểm thú vị. Ok vào bài viết nhanh vậy.

# Tóm lược paper
## [AI models collapse when trained on recursively generated data](https://www.nature.com/articles/s41586-024-07566-y)
Summary: This paper investigates the phenomenon of "model collapse," a degenerative process in which AI models trained on data generated by previous models lose information about the true underlying data distribution.

### Key Findings:

- Model Collapse Definition: Model collapse is defined as a process where AI models forget the true data distribution due to the pollution of training data with model-generated content.
- Causes: The main causes of model collapse are statistical approximation error, functional expressivity error, and functional approximation error.
- Universality: Model collapse affects various types of generative models, including large language models (LLMs), variational autoencoders (VAEs), and Gaussian mixture models (GMMs).
- Impact on LLMs: In LLMs, model collapse leads to a decrease in the quality and diversity of generated text over generations, with text becoming more repetitive and less aligned with human-generated data.
- Mitigation: Preserving access to original, human-generated data is crucial to mitigate model collapse. Distinguishing AI-generated data from human-generated data is also important.
### Implications:

- Model collapse poses a significant challenge to the long-term development of AI models.
- Reliance on AI-generated data for training can degrade AI capabilities.
- Preserving and curating human-generated data is essential.
- Transparency and provenance tracking of AI-generated content are needed.

## [Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data](https://arxiv.org/pdf/2404.01413)

Summary: This paper investigates the phenomenon of model collapse in generative AI models, where training on their own generated data leads to a decline in performance. It challenges the assumption that model collapse is inevitable by demonstrating that accumulating synthetic data alongside real data can prevent this issue.

## Key Findings:

- Accumulating Data Avoids Model Collapse: Empirical evidence from various generative models (language models, diffusion models, variational autoencoders) shows that accumulating synthetic data alongside real data prevents model collapse.
- Theoretical Explanation: A theoretical framework involving linear models confirms that accumulating data leads to a finite upper bound on test error, preventing the unbounded error growth observed in model collapse.
- Implications: The findings suggest that accumulating data is a promising approach to mitigate model collapse in generative AI. This has important implications for the future development and deployment of these models, as it highlights the importance of maintaining access to diverse and high-quality training data.
## Implications:

- The research provides empirical and theoretical evidence that accumulating data alongside real data can effectively mitigate model collapse in generative AI models. This finding has significant implications for the future development and deployment of generative models, emphasizing the importance of considering real-world data dynamics in model training.

# Một số vấn đề:

Một vấn đề đầu tiên gặp phải đối với bài viết ở [Natural](#ai-models-collapse-when-trained-on-recursively-generated-data) là họ đang tạo ra một cách hiểu sai cho cộng đồng về synthetic data. Điều này bộc lộ ở một vài điểm sau:
- Chỉ có 2 thực nghiệm chính được tiến hành trong bài báo là train 5 epochs với toàn bộ dữ liệu synthetic và train 10 epochs với dữ liệu kết hợp giữa synthetic + dữ liệu gốc (có vẻ hơi thiếu tổng quát)
- Dữ liệu synthetic ở đây chỉ được tạo ra bằng cách beam search 5-way. Có thể nói đây là 1 cách KD (knowledge distilation) hơn là synthetic data vì chúng rất ngây thơ.

Nhìn chung nhận định paper này không sai nhưng nó đang diễn đạt lại nhận định từ một nghiên cứu [trước đó](#is-model-collapse-inevitable-breaking-the-curse-of-recursion-by-accumulating-real-and-synthetic-data) (tất nhiên không có đạo văn gì ở đây cả vì chúng khác nhau ở cách thức cài đặt). Tuy nhiên tình huống buồn cười ở đây là vì nó đăng ở Natural nên mọi người bắt đầu cuống cuồng lên với nó :). 
Thật sự Synthetic data vẫn đang là 1 kỹ thuật được sử dụng nhiều nhưng ở ngay những nghiên cứu như LLama3.1 của Meta họ cũng đưa ra những tricks synthetic data hiệu quả thay vì ngây thơ như nghiên cứu này. Và sẽ thật thiếu xót nếu chúng ta không dùng synthetic data chỉ vì những nghiên cứu thế này :)
